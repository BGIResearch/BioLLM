# the param for the llm model, to init the foundation model.
model_used = "scgpt"
emb_type = 'cell' # gene/cell/gene-expression
model_file = '../../case/models/scgpt/best_model.pt'
model_param_file = '../../case/models/scgpt/args.json'
vocab_file = '../../case/models/scgpt/vocab.json'
# get embedding params
input_file = ''
output_dir = '../../case/result/zero-shot/'
pad_value = -2
mask_ratio = 0
device = 'cuda:0'
CLS = false  # celltype classification objective
ADV = false  # Adversarial training for batch correction
CCE = false  # Contrastive cell embedding objective
MVC = false  # Masked value prediction for cell embedding
ECS = false  # Elastic cell similarity objective
append_cls = true
do_preprocess = true
#filter_cell_by_counts = 3
#n_hvg = 1000
include_zero_gene = false
input_style = "binned"  # "normed_raw", "log1p", or "binned"
output_style = "binned"  # "normed_raw", "log1p", or "binned"
# settings for training
distributed = false
nlayers_cls = 3
do_mvc = false
do_dab = false
input_emb_style = "continuous"  # "category" or "continuous" or "scaling"
cell_emb_style = "cls"  # "avg-pool" or "w-pool" or "cls"
do_sample_in_train = false  # sample the bernoulli in training
per_seq_batch_sample = false
batch_size = 8