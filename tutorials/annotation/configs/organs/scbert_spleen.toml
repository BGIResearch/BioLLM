# the param for the llm model, to init the foundation model.
model_used = "scbert"
model_file = '../../case/models/scbert/panglao_pretrain.pth'
vocab_file = '../../case/models/scbert/gene_vocab.json'
g2v_file = '../../case/models/scbert/gene2vec_16906.npy'
# model params, always not change
bin_num = 7
embsize = 200
max_seq_len = 16907
batch_size = 3
use_g2v = true
GRADIENT_ACCUMULATION = 60
UNASSIGN_THRES = 0.0
# task params, user setting for the task
device = 'cuda:1'
distributed = true
finetune = true
# the input data info, for the preocess step
input_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/case/data/annotation/human/organs/spleen/train.h5ad'
output_dir = '../../case/result/anno/scbert/spleen/'
do_preprocess = true
label_key = 'cell_type_ontology_term_id'
# trainning params
lr = 0.001
epochs=30
early_stop=15
# wandb setting
weight_bias_track = true
project_name = 'biollm_annotation'
exp_name = 'scbert_spleen'
