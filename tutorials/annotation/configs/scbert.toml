# the param for the llm model, to init the foundation model.
model_used = "scbert"
model_file = '../../case/models/scbert/panglao_pretrain.pth'
vocab_file = '../../case/models/scbert/gene_vocab.json'
g2v_file = '../../case/models/scbert/gene2vec_16906.npy'
# model params, always not change
bin_num = 7
embsize = 200
max_seq_len = 16907
batch_size = 3
use_g2v = true
GRADIENT_ACCUMULATION = 60
UNASSIGN_THRES = 0.0
# task params, user setting for the task
device = 'cuda:1'
distributed = true
finetune = true
# the input data info, for the preocess step
input_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/finetune/cell_annotation/mye/scbert/reference_adata.h5ad'
test_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/finetune/cell_annotation/mye/scbert/query_adata.h5ad'
output_dir = '../../case/result/anno/scbert/mye/'
do_preprocess = false
label_key = 'cell_type'
# trainning params
lr = 0.001
epochs=50
early_stop=25
# wandb setting
weight_bias_track = true
project_name = 'biollm_annotation'
exp_name = 'scbert_mye'
