{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. get the cell embedding of scGPT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d4de6f4a4e9ebd1"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-27T03:36:40.594905Z",
     "start_time": "2025-03-27T03:35:19.957038800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/share/huadjyin/home/s_qiuping1/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/lightning/fabric/plugins/environments/xla.py:18: DeprecationWarning: `ModuleAvailableCache` is a special case of `RequirementCache`. Please use `RequirementCache(module=...)` instead.\n",
      "  from lightning.fabric.accelerators.tpu import _XLA_AVAILABLE, TPUAccelerator\n",
      "/home/share/huadjyin/home/s_qiuping1/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/lightning/fabric/__init__.py:36: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning.fabric')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "/home/share/huadjyin/home/s_qiuping1/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/pkg_resources/__init__.py:2553: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "/home/share/huadjyin/home/s_qiuping1/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/lightning/pytorch/__init__.py:36: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning.pytorch')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "/home/share/huadjyin/home/s_qiuping1/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/pkg_resources/__init__.py:2553: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "/home/share/huadjyin/home/s_qiuping1/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n",
      "  self.seed = seed\n",
      "/home/share/huadjyin/home/s_qiuping1/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n",
      "  self.dl_pin_memory_gpu_training = (\n",
      "/home/share/huadjyin/home/s_qiuping1/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/chex/_src/pytypes.py:53: DeprecationWarning: jax.core.Shape is deprecated. Use Shape = Sequence[int | Any].\n",
      "  Shape = jax.core.Shape\n",
      "/home/share/huadjyin/home/s_qiuping1/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/chex/_src/pytypes.py:54: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
      "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
      "  PRNGKey = jax.random.KeyArray\n",
      "/home/share/huadjyin/home/s_qiuping1/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/umap/__init__.py:9: ImportWarning: Tensorflow not installed; ParametricUMAP will be unavailable\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ntoken': 60697, 'd_model': 512, 'nhead': 8, 'd_hid': 512, 'nlayers': 12, 'nlayers_cls': 3, 'n_cls': 1, 'dropout': 0.2, 'pad_token': '<pad>', 'do_mvc': False, 'do_dab': False, 'use_batch_labels': False, 'num_batch_labels': None, 'domain_spec_batchnorm': False, 'input_emb_style': 'continuous', 'cell_emb_style': 'cls', 'mvc_decoder_style': 'inner product', 'ecs_threshold': 0.3, 'explicit_zero_prob': False, 'fast_transformer_backend': 'flash', 'pre_norm': False, 'vocab': GeneVocab(), 'pad_value': -2, 'n_input_bins': 51, 'use_fast_transformer': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params encoder.embedding.weight with shape torch.Size([60697, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params encoder.enc_norm.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params encoder.enc_norm.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params value_encoder.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params value_encoder.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params value_encoder.norm.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params value_encoder.norm.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params decoder.fc.0.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params decoder.fc.0.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params decoder.fc.2.weight with shape torch.Size([512, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params decoder.fc.2.bias with shape torch.Size([512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params decoder.fc.4.weight with shape torch.Size([1, 512])\n",
      "2025-03-27 11:36:05-loader_base[line-91]-INFO: Loading params decoder.fc.4.bias with shape torch.Size([1])\n",
      "2025-03-27 11:36:11-cell_emb_task[line-24]-INFO: Munch({'model_file': '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/case/models/scgpt/best_model.pt', 'model_param_file': '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/case/models/scgpt/args.json', 'vocab_file': '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/case/models/scgpt/vocab.json', 'pad_value': -2, 'mask_ratio': 0, 'append_cls': True, 'input_style': 'binned', 'output_style': 'binned', 'do_mvc': False, 'do_dab': False, 'input_emb_style': 'continuous', 'cell_emb_style': 'cls', 'do_sample_in_train': False, 'per_seq_batch_sample': False, 'distributed': False, 'input_file': '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/CFM/data/case/zero-shot/int/hPancreas/hPancreas.h5ad', 'output_dir': '/home/share/huadjyin/home/s_qiuping1/workspace/BioLLM1/demo/cell_emb/hPancreas/scgpt_1200', 'device': 'cuda', 'batch_size': 32, 'do_preprocess': True, 'max_seq_len': 1200, 'include_zero_gene': False, 'model_used': 'scgpt', 'emb_type': 'cell', 'var_key': '', 'obs_key': 'celltype', 'n_hvg': 0, 'batch_key': 'batch', 'data_source': '/scratch/ssd004/datasets/cellxgene/scb_strict/human', 'save_dir': '/scratch/ssd004/datasets/cellxgene/save/cellxgene_census_human-May23-08-36-2023', 'load_model': None, 'valid_size_or_ratio': 0.003, 'dist_backend': 'nccl', 'grad_accu_steps': 1, 'pad_token': '<pad>', 'n_bins': 51, 'training_tasks': 'both', 'dist_url': 'tcp://gpu188.cluster.local:53833', 'trunc_by_sample': True, 'vocab_path': '/scratch/ssd004/datasets/cellxgene/scFormer/scformer/tokenizer/default_census_vocab.json', 'rank': 0, 'eval_batch_size': 64, 'epochs': 6, 'lr': 0.0001, 'scheduler_interval': 100, 'scheduler_factor': 0.99, 'warmup_ratio_or_step': 10000.0, 'no_cls': True, 'no_cce': True, 'fp16': True, 'fast_transformer': True, 'nlayers': 12, 'nheads': 8, 'embsize': 512, 'd_hid': 512, 'dropout': 0.2, 'n_layers_cls': 3, 'log_interval': 9000, 'save_interval': 27000, 'mask_value': -1, 'USE_CLS': False, 'USE_CCE': False, 'MVC': True, 'USE_GENERATIVE_TRAINING': True, 'world_size': 16, 'local_rank': 0, 'gpu': 0})\n",
      "2025-03-27 11:36:11-scgpt[line-238]-INFO: start to get cell embedding!\n",
      "2025-03-27 11:36:11-data_handler[line-119]-INFO: match 14346/14362 genes in vocab of size 14362\n",
      "2025-03-27 11:36:20-scgpt_handler[line-29]-INFO: Binning data ...\n",
      "2025-03-27 11:36:40-scgpt[line-243]-INFO: get dataloader Done!\n",
      "Cell embedding:   0%|          | 0/462 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m config_file \u001B[38;5;241m=\u001B[39m i\n\u001B[1;32m     12\u001B[0m obj \u001B[38;5;241m=\u001B[39m CellEmbTask(config_file)\n\u001B[0;32m---> 13\u001B[0m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/BioLLM1/biollm/tasks/cell_emb/cell_emb_task.py:36\u001B[0m, in \u001B[0;36mCellEmbTask.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mvar_key:\n\u001B[1;32m     34\u001B[0m     adata\u001B[38;5;241m.\u001B[39mvar_names \u001B[38;5;241m=\u001B[39m adata\u001B[38;5;241m.\u001B[39mvar[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mvar_key]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m---> 36\u001B[0m emb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43memb_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43memb_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m adata\u001B[38;5;241m.\u001B[39mobsm[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX_emb\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m emb\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39moutput_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/cell_emb.pk\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fd:\n",
      "File \u001B[0;32m~/workspace/BioLLM1/biollm/tasks/bio_task.py:205\u001B[0m, in \u001B[0;36mBioTask.llm_embedding\u001B[0;34m(self, emb_type, adata, gene_ids)\u001B[0m\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_bgi_emb(emb_type, adata, gene_ids)\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_obj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43memb_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgene_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgene_ids\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/BioLLM1/biollm/loader/scgpt.py:374\u001B[0m, in \u001B[0;36mScgpt.get_embedding\u001B[0;34m(self, emb_type, adata, gene_ids)\u001B[0m\n\u001B[1;32m    372\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_gene_embedding(gene_ids)\n\u001B[1;32m    373\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m emb_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcell\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 374\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_cell_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43madata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    376\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_gene_expression_embedding(adata)\n",
      "File \u001B[0;32m~/workspace/BioLLM1/biollm/loader/scgpt.py:248\u001B[0m, in \u001B[0;36mScgpt.get_cell_embedding\u001B[0;34m(self, adata, pool_type)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad(), torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast(enabled\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    247\u001B[0m     count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 248\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch_data \u001B[38;5;129;01min\u001B[39;00m tqdm(data_loader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCell embedding\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    249\u001B[0m         input_gene_ids \u001B[38;5;241m=\u001B[39m batch_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgene_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    250\u001B[0m         input_values \u001B[38;5;241m=\u001B[39m batch_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[0;32m~/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/torch/utils/data/dataloader.py:442\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/torch/utils/data/dataloader.py:388\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    387\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[0;32m--> 388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/app/miniconda3/envs/scgpt/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1043\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[0;34m(self, loader)\u001B[0m\n\u001B[1;32m   1036\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[1;32m   1038\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[1;32m   1041\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[1;32m   1042\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[0;32m-> 1043\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1044\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[1;32m   1045\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[0;32m~/app/miniconda3/envs/scgpt/lib/python3.9/multiprocessing/process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[1;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    120\u001B[0m _cleanup()\n\u001B[0;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[0;32m~/app/miniconda3/envs/scgpt/lib/python3.9/multiprocessing/context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/app/miniconda3/envs/scgpt/lib/python3.9/multiprocessing/context.py:277\u001B[0m, in \u001B[0;36mForkProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_fork\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[0;32m--> 277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/app/miniconda3/envs/scgpt/lib/python3.9/multiprocessing/popen_fork.py:19\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinalizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_launch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/app/miniconda3/envs/scgpt/lib/python3.9/multiprocessing/popen_fork.py:66\u001B[0m, in \u001B[0;36mPopen._launch\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     64\u001B[0m parent_r, child_w \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpipe()\n\u001B[1;32m     65\u001B[0m child_r, parent_w \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpipe()\n\u001B[0;32m---> 66\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpid \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfork\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpid \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mOSError\u001B[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "from biollm.tasks.cell_emb.cell_emb_task import CellEmbTask\n",
    "\n",
    "\n",
    "files = [\n",
    "    '/home/share/huadjyin/home/s_qiuping1/workspace/BioLLM1/biollm/config/embeddings/cell_emb/scgpt_1200/hpancreas.toml',\n",
    "    '/home/share/huadjyin/home/s_qiuping1/workspace/BioLLM1/biollm/config/embeddings/cell_emb/scgpt_1200/liver.toml',\n",
    "    '/home/share/huadjyin/home/s_qiuping1/workspace/BioLLM1/biollm/config/embeddings/cell_emb/scgpt_1200/kidney.toml',\n",
    "    '/home/share/huadjyin/home/s_qiuping1/workspace/BioLLM1/biollm/config/embeddings/cell_emb/scgpt_1200/hpbmc.toml',\n",
    "]\n",
    "for i in files:\n",
    "    config_file = i\n",
    "    obj = CellEmbTask(config_file)\n",
    "    obj.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
