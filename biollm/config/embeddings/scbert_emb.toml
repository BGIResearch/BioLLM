# the param for the llm model, to init the foundation model.
model_used = "scbert"
emb_type = 'gene' # gene/cell/gene-expression
model_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/scBERT/ckpt/panglao_pretrain.pth'
vocab_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/train_data/gene2vec/gene_vocab.json'
# test h5ad, sc express matrix
input_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/downstream_tasks/test/grn/data/Immune_ALL_human.h5ad'  # h5ad for the sc express matrix
model_type = 'scbert'  # scgpt/scmamba/scbert
output_dir = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/biollm/result/embeddings/'
device = 'cuda:1'
bin_num = 7
embsize = 200
distributed = false
batch_size = 8
# the input data info, for the preocess step
do_preprocess = false
max_seq_len = 16907
use_g2v = true
g2v_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/train_data/gene2vec/gene2vec_16906.npy'
