model_used = 'scgpt' # scgpt/scbert/scmamba
emb_type = 'gene-expression' # universal/gene-expression
model_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/case/models/scgpt/best_model.pt'
model_param_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/case/models/scgpt/args.json'
vocab_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/case/models/scgpt/vocab.json'

#data_dir = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/finetune/gears_data/norman_gears'
#result_dir = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/finetune/gears_data/model/norman_scgpt'

# gears args
data_dir = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/finetune/gears_data/norman_scgpt'
data_name = 'norman'
split = 'simulation'
seed=1
train_gene_set_size=0.75
batch_size=32
test_batch_size=128
device = 'cuda'
pretrained_emb_size = 512 # same with pretrain
hidden_size = 64 # same with pretrain
epochs = 10
lr = 1e-3
result_dir = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/finetune/gears_data/norman_scgpt_exp'
#result_dir = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/finetune/gears_data/model/mamba'
use_pretrained = true
pretrain_freeze = false
finetune = true
weight_bias_track = true
proj_name = 'gears'
project_name = 'gears'
exp_name = 'norman_scgpt_exp'