model_used = "scbert"
model_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/scBERT/ckpt/panglao_pretrain.pth'
vocab_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/train_data/gene2vec/gene_vocab.json'
bin_num = 7
embsize = 200
max_seq_len = 16907
use_g2v = true
g2v_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/train_data/gene2vec/gene2vec_16906.npy'
# gears args
data_dir = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/finetune/gears_data/norman_scbert'
data_name = 'norman'
split = 'simulation'
seed=52
train_gene_set_size=0.7
batch_size=32
test_batch_size=128
device = '0'
hidden_size = 200 # same with pretrain
epochs = 10
lr = 1e-3
result_dir = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/finetune/gears_data/norman_scbert'
use_pretrained = true
pretrain_freeze = false
emb_type = 'universal' # universal/gene-expression

