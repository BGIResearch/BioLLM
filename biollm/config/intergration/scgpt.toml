# the param for the llm model, to init the foundation model.
model_used = "scgpt"
model_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/downstream_tasks/test/grn/model/scgpt_bc/best_model.pt'
#model_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/biollm/result/intergration/PBMC10K/best_model.pt'
model_param_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/downstream_tasks/test/grn/model/scgpt_bc/args.json'
vocab_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/downstream_tasks/test/grn/model/scgpt_bc/vocab.json'
# test h5ad, sc express matrix
input_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/data/finetune/Integration/scgpt/PBMC10K.h5ad'  # h5ad for the sc express matrix
output_dir = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/biollm/result/intergration/PBMC10K'
do_preprocess = true
data_is_raw = true
n_hvg = 1200
filter_gene_by_counts = 3
filter_cell_by_counts = false
batch_key = 'str_batch'
append_cls = true
distributed = false
finetune = true
predicted = true
device = 'cuda:1'
mask_ratio = 0.4
include_zero_gene = false
max_seq_len = 1201
input_style = "binned"  # "normed_raw", "log1p", or "binned"
output_style = "binned"  # "normed_raw", "log1p", or "binned"
# settings for training
nlayers_cls = 3
pad_value = -2
do_mvc = true
do_dab = true
dab_weight=1.0
domain_spec_batchnorm = true
ecs_threshold = 0.8
input_emb_style = "continuous"  # "category" or "continuous" or "scaling"
cell_emb_style = "cls"  # "avg-pool" or "w-pool" or "cls"
lr = 0.0001
batch_size = 64
eval_batch_size = 128
epochs = 15
schedule_interval = 1
schedule_ratio = 0.9
fast_transformer = true
fast_transformer_backend = "flash"
dropout = 0.2
log_interval = 100
save_eval_interval=5
pre_norm=false
explicit_zero_prob = true
per_seq_batch_sample = true
sort_seq_batch=true