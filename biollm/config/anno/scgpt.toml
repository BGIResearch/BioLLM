# the param for the llm model, to init the foundation model.
model_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/case/models/scgpt/best_model.pt'
model_param_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/case/models/scgpt/args.json'
vocab_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/case/models/scgpt/vocab.json'
pad_value = -2
mask_ratio = 0
append_cls = true
input_style = "binned"  # "normed_raw", "log1p", or "binned"
output_style = "binned"  # "normed_raw", "log1p", or "binned"
do_mvc = false
do_dab = false
input_emb_style = "continuous"  # "category" or "continuous" or "scaling"
cell_emb_style = "cls"  # "avg-pool" or "w-pool" or "cls"
do_sample_in_train = false  # sample the bernoulli in training
per_seq_batch_sample = false

# task params
distributed = false
input_file = '/home/share/huadjyin/home/s_qiuping1/workspace/omics_model/bio_model/biollm/case/data/annotation/human/organs/eye/train.h5ad'
output_dir = '/home/share/huadjyin/home/s_qiuping1/workspace/BioLLM2/demo/annotation/eye/scgpt'
device = 'cuda'
batch_size = 32
do_preprocess = true
max_seq_len = 3000
include_zero_gene = false

## cell embedding
model_used = "scgpt"
emb_type = 'cell'

## expert model train params
cls_nlayers=3
label_key='cell_type'
lr=0.0001
epochs=10
finetune=true
